{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_average(sent):\n",
    "    sents_emd = []\n",
    "    for s in sent:\n",
    "        words = str(s).lower().split()\n",
    "        words = [w for w in words if w not in STOPWORDS]\n",
    "#         print words\n",
    "        sent_emd = []\n",
    "        for w in words:\n",
    "            try:\n",
    "                sent_emd.append(model[w])\n",
    "            except:\n",
    "                continue\n",
    "        sent_emd = np.array(sent_emd)\n",
    "        sum_ = sent_emd.sum(axis=0)\n",
    "        result = sum_/np.sqrt((sum_**2).sum())\n",
    "        sents_emd.append(result)\n",
    "    return sents_emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(sent):\n",
    "    word_counter = {}\n",
    "    sentences = []\n",
    "    total_count = 0\n",
    "    for s in sent:\n",
    "        words = str(s).lower().split()\n",
    "        words = [w for w in words if w not in STOPWORDS]\n",
    "        for w in words:\n",
    "            if w in word_counter:\n",
    "                word_counter[w] = word_counter[w] + 1\n",
    "            else:\n",
    "                word_counter[w] = 1\n",
    "        sentences.append(words)\n",
    "        total_count = total_count + len(words)\n",
    "#     print total_count, word_counter, sentences\n",
    "    no_of_sentences = len(sentences)\n",
    "    sents_emd = []\n",
    "    for s in sentences:\n",
    "        sent_emd = []\n",
    "        for word in s:\n",
    "            tf = word_counter[word]/float(len(s))\n",
    "            idf = np.log(no_of_sentences/float(1+ word_counter[word]))\n",
    "            try:\n",
    "                emd = tf*idf*model[word]\n",
    "                sent_emd.append(emd)\n",
    "            except:\n",
    "                continue\n",
    "        sent_emd = np.array(sent_emd)\n",
    "        sum_ = sent_emd.sum(axis=0)\n",
    "        result = sum_/np.sqrt((sum_**2).sum())\n",
    "        sents_emd.append(result)\n",
    "    return sents_emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_inverse_frequency(sent, a=None):\n",
    "    # Here sent is list of sentences.\n",
    "    word_counter = {}\n",
    "    sentences = []\n",
    "    total_count = 0\n",
    "    for s in sent:\n",
    "        words = str(s).lower().split()\n",
    "        words = [w for w in words if w not in STOPWORDS]\n",
    "        for w in words:\n",
    "            if w in word_counter:\n",
    "                word_counter[w] = word_counter[w] + 1\n",
    "            else:\n",
    "                word_counter[w] = 1\n",
    "        sentences.append(words)\n",
    "        total_count = total_count + len(words)\n",
    "    # print total_count, word_counter, sentences\n",
    "    no_of_sentences = len(sentences)\n",
    "    sents_emd = []\n",
    "    for s in sentences:\n",
    "        sent_emd = []\n",
    "        for word in s:\n",
    "            try:\n",
    "                if a is None:\n",
    "                    a = 0.001\n",
    "                    emd = (a/(a + (word_counter[word]/total_count)))*model[word]\n",
    "                else:\n",
    "                    emd = (a/(a + (word_counter[word]/total_count)))*model[word]\n",
    "                # print emd\n",
    "            except:\n",
    "                continue\n",
    "            sent_emd.append(emd)\n",
    "        sum_ = np.array(sent_emd).sum(axis=0)\n",
    "#         print sum_\n",
    "        sentence_emd = sum_/float(no_of_sentences)\n",
    "        sents_emd.append(sentence_emd)\n",
    "    u  = np.array(svds(sents_emd, k=1))\n",
    "    u = u[2]\n",
    "    new_sents_emd = []\n",
    "    for s in sents_emd:\n",
    "        s = s - s.dot(u.transpose()).dot(u)\n",
    "        #print s\n",
    "        new_sents_emd.append(s)\n",
    "    return new_sents_emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"this is a sample sentence with cat and dog\"\n",
    "s2 = \"there was a time when computers were very expensive\"\n",
    "s3 = \"a sample sentence with cute dog\"\n",
    "s4 = \"I'm eagerly waiting for Avengers Infinity War\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [s1,s2,s3,s4]\n",
    "sentences_emd1 = smooth_inverse_frequency(sentences)\n",
    "sentences_emd2 = tf_idf(sentences)\n",
    "sentences_emd3 = simple_average(sentences)\n",
    "# print sentences_emd1, sentences_emd2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for simple average\n",
    "a = \"\"\n",
    "for i in sentences_emd3:\n",
    "    for s in i:\n",
    "        a = a + str(s) + '\\t'\n",
    "    a = a + '\\n'\n",
    "#print a\n",
    "with open(\"record3.tsv\", \"w\") as record_file:\n",
    "    record_file.write(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Average: \n",
    "<img src=\"AVG.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for TF-IDF\n",
    "a = \"\"\n",
    "for i in sentences_emd2:\n",
    "    for s in i:\n",
    "        a = a + str(s) + '\\t'\n",
    "    a = a + '\\n'\n",
    "#print a\n",
    "with open(\"record2.tsv\", \"w\") as record_file:\n",
    "    record_file.write(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF: \n",
    "<img src=\"TFIDF.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for SIF\n",
    "a = \"\"\n",
    "for i in sentences_emd1:\n",
    "    for s in i:\n",
    "        a = a + str(s) + '\\t'\n",
    "    a = a + '\\n'\n",
    "#print a\n",
    "with open(\"record1.tsv\", \"w\") as record_file:\n",
    "    record_file.write(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIF: \n",
    "<img src=\"SIF.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
